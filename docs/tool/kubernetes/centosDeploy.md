# æ­å»ºå•masteré›†ç¾¤ã€centosç¦»çº¿éƒ¨ç½²ã€‘


::: tip å‚è€ƒèµ„æ–™
[Kubernetes(k8s)ä¸ªäººå­¦ä¹ ç¬”è®°](http://www.codedog.fun/2020/04/12/Kubernetes(k8s)%E4%B8%AA%E4%BA%BA%E7%AC%94%E8%AE%B0(%E6%9B%B4%E6%96%B0%E4%B8%AD)/)
:::

## ä¸€. éƒ¨ç½²æ–¹å¼

### å•masteré›†ç¾¤

![å•masteré›†ç¾¤](http://cdn.chemputer.top/notebook/k8s/singletonArch.png)


### å¤šmasteré›†ç¾¤

![å•masteré›†ç¾¤](http://cdn.chemputer.top/notebook/k8s/clusterArch.png)

## äºŒ. ç”Ÿäº§ç¯å¢ƒk8så¹³å°è§„åˆ’

OS: `centOS 7.7`

Kubernetes: `v1.16`

Docker: `v18.09`

## ä¸‰. æœåŠ¡å™¨ç¡¬ä»¶é…ç½®æ¨è

æ ¹æ®å®é™…æƒ…å†µè‡ªè¡Œè°ƒé…ï¼Œä¸€èˆ¬æ¥è¯´ï¼Œ`node` èŠ‚ç‚¹é…ç½®è¦ä¼˜äº `master` èŠ‚ç‚¹

## å››. å®˜æ–¹æä¾›ä¸‰ç§éƒ¨ç½²æ–¹å¼
 
### 1. minikube 

æœ¬åœ°å¿«é€Ÿè¿è¡Œå•ç‚¹k8sï¼Œä»…ç”¨äºå°è¯•å’Œå­¦ä¹ 

### 2. kubeadmå·¥å…· 

`kubeadm init` + `kubeadm join` ç”¨äºå¿«é€Ÿéƒ¨ç½²k8sé›†ç¾¤ï¼ˆç¼ºç‚¹ï¼šä¸æ¸…æ¥šé…ç½® ç†Ÿç»ƒä¹‹åæ¨èï¼‰

### 3. äºŒè¿›åˆ¶ ğŸ‘

æ‰‹åŠ¨éƒ¨ç½²æ¯ä¸ªç»„ä»¶ï¼Œç»„æˆk8sé›†ç¾¤

::: tip ä¼˜ç‚¹
æ–°æ‰‹å¿…ç»ä¹‹è·¯ï¼Œå¯¹äºäº†è§£ `k8s` æ¶æ„æœ‰æå¤§å¸®åŠ©
:::


## äº”. æœåŠ¡å™¨å‡†å¤‡å·¥ä½œ

### 1. ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆè™šæ‹Ÿæœºï¼‰

``` bash
vi /etc/sysconfig/network-scripts/ifcfg-ens33
```

```
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=dhcp
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens33
UUID=099b8485-5c12-4ac0-8463-8e213efc4347
DEVICE=ens33
ONBOOT=yes    #å°†noæ”¹ä¸ºyes
```

### 2. åˆå§‹åŒ–æœåŠ¡å™¨

| hostname | ip | å®‰è£…ç»„ä»¶ |
| --- | --- | --- |
| k8s-master01 | 172.16.199.136 | `kube-apiserver`, `kube-controller-manager`, `kube-scheduler`, `etcd` |
| k8s-node01  | 172.16.199.137 | `kubelet`, `kube-proxy`, `docker`, `flannel`, `etcd` |
| k8s-node02  | 172.16.199.138 | `kubelet`, `kube-proxy`, `docker`, `flannel`, `etcd` |

### 3. å…³é—­é˜²ç«å¢™

``` bash
systemctl stop firewalld
systemctl disable firewalld
```

### 4. å…³é—­äº¤æ¢åˆ†åŒºï¼ˆè‹¥ä¸å…³é—­ï¼Œåˆ™æœ‰å¯èƒ½å¯¼è‡´k8sæœåŠ¡èµ·ä¸æ¥ï¼‰

``` bash
swapoff -a # ä¸´æ—¶å…³é—­
vi /etc/fstab # æ°¸ä¹…å…³é—­ï¼ˆæ³¨é‡Šæ‰ #/dev/mapper/centos-swap swap è¿™ä¸€è¡Œï¼‰
free -m # æŸ¥çœ‹swapåˆ†åŒºçŠ¶æ€
```

```
#
# /etc/fstab
# Created by anaconda on Fri Jun  5 10:52:04 2020
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
/dev/mapper/centos-root /                       xfs     defaults        0 0
UUID=0fc5f6fe-5e33-4f7a-af20-802dc698f8cc /boot                   xfs     defaults        0 0
#/dev/mapper/centos-swap swap                    swap    defaults        0 0     
```

### 5. é…ç½®ä¸»æœºå

```
hostnamectl set-hostname k8s-master01
hostnamectl set-hostname k8s-node01
hostnamectl set-hostname k8s-node02
```

### 6. é…ç½®åç§°è§£æ

``` bash
vi /etc/hosts
```

```
# ä¸‰ä¸ªèŠ‚ç‚¹æ·»åŠ  å¦‚ä¸‹å†…å®¹
172.16.199.136 k8s-master01
172.16.199.137 k8s-node01
172.16.199.138 k8s-node02
```

### 7. å…³é—­selinux

``` bash
setenforce 0 # ä¸´æ—¶å…³é—­
vi /etc/selinux/config # å°†SELINUX=enforcing ä¿®æ”¹ä¸º SELINUX=disabled
```

```
# This file controls the state of SELinux on the system.
# SELINUX= can take one of these three values:
#     enforcing - SELinux security policy is enforced.
#     permissive - SELinux prints warnings instead of enforcing.
#     disabled - No SELinux policy is loaded.
SELINUX=disabled
# SELINUXTYPE= can take one of three two values:
#     targeted - Targeted processes are protected,
#     minimum - Modification of targeted policy. Only selected processes are protected.
#     mls - Multi Level Security protection.
SELINUXTYPE=targeted
```


### 8. é…ç½®æ—¶é—´åŒæ­¥ 

:::tip è¯´æ˜
1. é€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºæœåŠ¡å™¨ï¼Œå‰©ä¸‹çš„ä½œä¸ºå®¢æˆ·ç«¯ï¼ˆæ­¤å¤„é€‰æ‹©master01ä¸ºæ—¶é—´æœåŠ¡å™¨çš„æœåŠ¡ç«¯
å…¶ä»–çš„ä¸ºæ—¶é—´æœåŠ¡å™¨çš„å®¢æˆ·ç«¯ï¼‰
2. å¿…é¡»ä¿è¯æ‰€æœ‰æœåŠ¡å™¨æ—¶é—´åŒæ­¥ï¼Œè‹¥ä¸åŒæ­¥ï¼Œå¯åˆ°å¯¼è‡´ä¾‹å¦‚è¯ä¹¦çš„ä¸åŒæ­¥
:::


1. é…ç½® `k8s-master01`

``` bash
yum install chrony -y
vi /etc/chrony.conf
```

```
# ä¿®æ”¹/etc/chrony.conf

# Please consider joining the pool (http://www.pool.ntp.org/join.html).
server 127.127.1.0 iburst #æŒ‡å®šä¸Šæ¸¸æœåŠ¡å™¨åœ°å€ï¼Œæ­¤å¤„ç”±äºæ˜¯masterèŠ‚ç‚¹ï¼ŒæŒ‡å®šè‡ªå·±å³å¯
# Allow NTP client access from local network.
allow 172.16.199.0/24     #ä¿®æ”¹ä¸ºè‡ªå·±çš„ç½‘æ®µ
# Serve time even if not synchronized to a time source.
local stratum 10          #å»æ‰æ³¨é‡Š
```
    
``` bash
systemctl start chronyd
systemctl enable chronyd
ss -unl | grep 123 # æŸ¥çœ‹
```

2. é…ç½® `k8s-node01`/ `node02`

``` bash
yum install chrony -y
vi /etc/chrony.conf
```

```
# ä¿®æ”¹/etc/chrony.conf

# Please consider joining the pool (http://www.pool.ntp.org/join.html).
     server 172.16.199.136 iburst #æŒ‡å®šä¸Šæ¸¸æœåŠ¡å™¨ï¼Œä¿®æ”¹ä¸ºk8s-master01èŠ‚ç‚¹ip  
```
     
``` bash
systemctl start chronyd
systemctl enable chronyd
```

3. éªŒè¯æ˜¯å¦æˆåŠŸ

``` bash
chronyc sources # æŸ¥çœ‹
# è‹¥æ˜¯^? è¡¨æ˜æ²¡æœ‰è®¾ç½®æˆåŠŸ
# è‹¥æ˜¯^* è¡¨æ˜åŒæ­¥æˆåŠŸ
```

## å…­. ä¸ºetcdå’Œapiserverè‡ªç­¾sslè¯ä¹¦

```
åŠ å¯†
* å¯¹ç§°åŠ å¯†ï¼šåŠ å¯†è§£å¯†ç”¨ç›¸åŒçš„ç§˜é’¥
* éå¯¹ç§°åŠ å¯†ï¼šå…¬é’¥ + ç§é’¥
* å•å‘åŠ å¯†ï¼šåªèƒ½åŠ å¯†ï¼Œä¸èƒ½è§£å¯†ï¼ˆmd5ï¼‰

sslè¯ä¹¦æ¥æº
* ç½‘ç»œç¬¬ä¸‰æ–¹æœºæ„è´­ä¹°ï¼Œé€šå¸¸è¿™ç§è¯ä¹¦ç”¨äºè®©å¤–éƒ¨ç”¨æˆ·è®¿é—®ä½¿ç”¨
* è‡ªç­¾è¯ä¹¦ï¼ˆè‡ªå·±ç»™è‡ªå·±å‘è¯ä¹¦ï¼‰ï¼Œé€šå¸¸ç”¨äºå†…éƒ¨ç¯å¢ƒ

sslä¸€äº›æ¦‚å¿µ
* ç«¯å®ä½“ï¼ˆç”³è¯·è€…ï¼‰
* æ³¨å†Œæœºæ„ï¼ˆRCï¼‰
* ç­¾è¯æœºæ„ï¼ˆCAï¼‰
* è¯ä¹¦æ’¤é”€åˆ—è¡¨ï¼ˆCRLï¼‰
* è¯ä¹¦å­˜å–åº“

è‡ªå»ºCA
* openssl
* cfssl (æœ¬æ¬¡æ­å»ºä½¿ç”¨æ–¹æ³•)
```

1. ä¸‹è½½cfsslå·¥å…·

``` bash
wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64
mv cfssl_linux-amd64 /usr/local/bin/cfssl
mv cfssljson_linux-amd64 /usr/local/bin/cfssljson
mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo
```

2. ç¼–å†™ä¸‰ä¸ªjsonæ–‡ä»¶

``` bash
# vi /root/TLS/etcd/ca-config.json
{
  "signing": {
    "default": {
      "expiry": "87600h"
    },
    "profiles": {
      "www": {
         "expiry": "87600h",
         "usages": [
            "signing",
            "key encipherment",
            "server auth",
            "client auth"
        ]
      }
    }
  }
}

# vi /root/TLS/etcd/ca-csr.json
{
    "CN": "etcd CA",
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "Beijing",
            "ST": "Beijing"
        }
    ]
}

# vi root/TLS/etcd/server-csr.json
# å¡«å†™è¡¨å•â€“å†™æ˜etcdæ‰€åœ¨èŠ‚ç‚¹çš„ip
# hostsè¡¨æ˜å½“å‰è¯ä¹¦é¢å‘ç»™å“ªå‡ ä¸ªä¸»æœº

{
    "CN": "etcd",
    "hosts": [ 
        "172.16.199.136",
        "172.16.199.137",
        "172.16.199.138"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "BeiJing",
            "ST": "BeiJing"
        }
    ]
}
```

3. åˆ›å»ºè¯ä¹¦é¢å‘æœºæ„

``` bash
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -
```

![åˆ›å»ºè¯ä¹¦é¢å‘æœºæ„](http://cdn.chemputer.top/notebook/k8s/cfssl.jpg)

``` bash
# ä¼šç”Ÿæˆä¸€å¯¹caçš„ç§˜é’¥
ls *pem
ca-key.pem ca.pem  
```

4. å‘è¯ä¹¦é¢å‘æœºæ„ç”³è¯·è¯ä¹¦

``` bash
cfssl gencert \
-ca=ca.pem \
-ca-key=ca-key.pem \
-config=ca-config.json \
-profile=www \
server-csr.json | cfssljson -bare server
```

``` bash
# ä¼šæœ‰4ä¸ªpemæ–‡ä»¶
[root@k8s-master01 etcd]# ll *pem  
ca-key.pem #caè¯ä¹¦
ca.pem #caè¯ä¹¦
server-key.pem #etcdè¯ä¹¦
server.pem #etcdè¯ä¹¦
```

## ä¸ƒ. etcdæ•°æ®åº“é›†ç¾¤éƒ¨ç½²

1. `github` ä¸‹è½½ `3.2.28` ç‰ˆæœ¬çš„ `etcd`

::: tip è¯´æ˜
æœ‰etcdçš„nodeä¸Šéƒ½è¦éƒ¨ç½²ï¼Œæ³¨æ„æ–‡ä»¶å¤¹çš„åå­—å’Œä½ç½®ï¼Œä¸æ˜¯éšä¾¿å‘½åå’Œæ”¾ç½®çš„
:::

``` bash
wget https://github.com/etcd-io/etcd/releases/download/v3.2.28/etcd-v3.2.28-linux-amd64.tar.gz
tar -zxvf etcd-v3.2.28-linux-amd64.tar.gz

mkdir /opt/etcd/{cfg,bin,ssl} -p. #åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå‘½ä»¤æ–‡ä»¶ï¼Œè¯ä¹¦
mv etcd-v3.2.28-linux-amd64/{etcd,etcdctl} /opt/etcd/bin #å°†æ–‡ä»¶ç§»åŠ¨è‡³æŒ‡å®šç›®å½•
```

::: tip çŸ¥è¯†ç‚¹
`centos6`: `systemV` é£æ ¼æœåŠ¡ç®¡ç†è„šæœ¬ç›®å½• `/etc/rc.d/rcN.d`  

`N` è¡¨ç¤º `0 1 2 3 4 5 6` æœåŠ¡è¿è¡Œçº§åˆ«

`centos7`: `systemd` æœåŠ¡ç®¡ç†è„šæœ¬ç›®å½• `/usr/lib/systemd/system`
:::

2. åˆ›å»º `etcd.conf` æ–‡ä»¶ 

``` bash
# vi /opt/etcd/cfg/etcd.conf 

#k8s-master01
#[Member]
ETCD_NAME="etcd-1"
ETCD_DATA_DIR="/var/lib/etcd/default.etcd"
ETCD_LISTEN_PEER_URLS="https://172.16.199.136:2380"
ETCD_LISTEN_CLIENT_URLS="https://172.16.199.136:2379"

#[Clustering]
ETCD_INITIAL_ADVERTISE_PEER_URLS="https://172.16.199.136:2380"
ETCD_ADVERTISE_CLIENT_URLS="https://172.16.199.136:2379"
ETCD_INITIAL_CLUSTER="etcd-1=https://172.16.199.136:2380,etcd-2=https://172.16.199.137:2380,etcd-3=https://172.16.199.138:2380"
ETCD_INITIAL_CLUSTER_TOKEN="etcd-cluster" 
ETCD_INITIAL_CLUSTER_STATE="new"
```

``` bash
#ETCD_NAME èŠ‚ç‚¹åç§°,node01æ”¹ä¸ºetcd-2ï¼Œnode02æ”¹ä¸ºetcd-3
#ETCD_DATA_DIR æ•°æ®ç›®å½•
#ETCD_LISTEN_PEER_URLS é›†ç¾¤é€šä¿¡ç›‘å¬åœ°å€,æ¥å—å…¶ä»–etcdæ•°æ®
#ETCD_LISTEN_CLIENT_URLS å®¢æˆ·ç«¯è®¿é—®ç›‘å¬åœ°å€,æ¥å—é™¤etcdä¹‹å¤–ï¼Œå’Œå¤–éƒ¨èŠ‚ç‚¹é€šè®¯
#ETCD_INITIAL_ADVERTISE_PEER_URLS é›†ç¾¤é€šå‘Šåœ°å€
#ETCD_ADVERTISE_CLIENT_URLS å®¢æˆ·ç«¯é€šå‘Šåœ°å€
#ETCD_INITIAL_CLUSTER é›†ç¾¤èŠ‚ç‚¹åœ°å€
#ETCD_INITIAL_CLUSTER_TOKEN é›†ç¾¤Token,èŠ‚ç‚¹é€šè®¯æ—¶çš„è®¤è¯tokenï¼ŒèŠ‚ç‚¹ä¿æŒä¸€è‡´
#ETCD_INITIAL_CLUSTER_STATE åŠ å…¥é›†ç¾¤çš„å½“å‰çŠ¶æ€ï¼Œnewæ˜¯æ–°é›†ç¾¤ï¼Œexistingè¡¨ç¤ºåŠ å…¥å·²æœ‰é›†ç¾¤
```


3. åˆ›å»º `etcd.service` æ–‡ä»¶

``` bash
vi /usr/lib/systemd/system/etcd.service
```

```
[Unit]
Description=Etcd Server
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
EnvironmentFile=/opt/etcd/cfg/etcd.conf
ExecStart=/opt/etcd/bin/etcd \
--name=${ETCD_NAME} \
--data-dir=${ETCD_DATA_DIR} \
--listen-peer-urls=${ETCD_LISTEN_PEER_URLS} \
--listen-client-urls=${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \
--advertise-client-urls=${ETCD_ADVERTISE_CLIENT_URLS} \
--initial-advertise-peer-urls=${ETCD_INITIAL_ADVERTISE_PEER_URLS} \
--initial-cluster=${ETCD_INITIAL_CLUSTER} \
--initial-cluster-token=${ETCD_INITIAL_CLUSTER_TOKEN} \
--initial-cluster-state=new \
--cert-file=/opt/etcd/ssl/server.pem \
--key-file=/opt/etcd/ssl/server-key.pem \
--peer-cert-file=/opt/etcd/ssl/server.pem \
--peer-key-file=/opt/etcd/ssl/server-key.pem \
--trusted-ca-file=/opt/etcd/ssl/ca.pem \
--peer-trusted-ca-file=/opt/etcd/ssl/ca.pem
Restart=on-failure
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

4. å°†ä¹‹å‰ç”Ÿæˆçš„è¯ä¹¦æ‹·è´åˆ°å›ºå®šçš„ç›®å½•

``` bash
cp /root/TLS/etcd/{ca,server,server-key}.pem /opt/etcd/ssl #æ‹·è´ç”Ÿæˆçš„è¯ä¹¦
```

5. å¯åŠ¨å¹¶è®¾ç½®å¼€æœºå¯åŠ¨

``` bash
systemctl start etcd
systemctl enable etcd
```

> å¯åŠ¨çš„æ—¶å€™å…ˆå¯åŠ¨å­èŠ‚ç‚¹çš„etcd

``` bash
#ä¸ä½¿ç”¨åˆ«å
cp #ç›¸å½“äº cp -i 
alias #æŸ¥çœ‹ç³»ç»Ÿä¸­çš„åˆ«å
unalias cp  #ä¸ä½¿ç”¨åˆ«å
\cp         #ä¸ä½¿ç”¨åˆ«å
```


6. æ£€æŸ¥é›†ç¾¤ä¸­çš„ `etcd` æ˜¯å¦æ­£å¸¸å·¥ä½œï¼ˆåœ¨ä¸»ä»èŠ‚ç‚¹ä¸Šéƒ½æµ‹è¯•ä¸€ä¸‹ï¼‰

``` bash
/opt/etcd/bin/etcdctl \
--ca-file=/opt/etcd/ssl/ca.pem \
--cert-file=/opt/etcd/ssl/server.pem \
--key-file=/opt/etcd/ssl/server-key.pem \
--endpoints="https://172.16.199.136:2379,https://172.16.199.137:2379,https://172.16.199.138:2379" \
cluster-health
```

``` bash
# ä¸‰ä¸ªèŠ‚ç‚¹å‡æ­£å¸¸
member 6dae76cecb4bcc84 is healthy: got healthy result from https://172.16.199.138:2379
member 9c12fda2a7536f4e is healthy: got healthy result from https://172.16.199.136:2379
member df2477b7bface443 is healthy: got healthy result from https://172.16.199.137:2379
```


## å…«. éƒ¨ç½²masterç»„ä»¶

1. ç”Ÿæˆè¯ä¹¦,ç¼–å†™ `4` ä¸ª `json` æ–‡ä»¶ 

``` bash
# vi /root/TLS/k8s/ca-config.json
{
  "signing": {
    "default": {
      "expiry": "87600h"
    },
    "profiles": {
      "kubernetes": {
         "expiry": "87600h",
         "usages": [
            "signing",
            "key encipherment",
            "server auth",
            "client auth"
        ]
      }
    }
  }
}

# vi /root/TLS/k8s/ca-csr.json
{
    "CN": "kubernetes",
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "Beijing",
            "ST": "Beijing",
            "O": "k8s",
            "OU": "System"
        }
    ]
}

# vi root/TLS/k8s/server-csr.json
{
    "CN": "kubernetes",
    "hosts": [ 
        "10.0.0.1",
        "127.0.0.1",
        "172.16.199.136",
        "kubernetes",
        "kubernetes.default",
        "kubernetes.default.svc",
        "kubernetes.default.svc.cluster",
        "kubernetes.default.svc.cluster.local"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
        {
            "C": "CN",
            "L": "BeiJing",
            "ST": "BeiJing",
            "O": "k8s",
            "OU": "System"
        }
    ]
}


# vi root/TLS/k8s/kube-proxy-csr.json

{
  "CN": "system:kube-proxy",
  "hosts": [],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}

```

``` bash
cfssl gencert -initca ca-csr.json | cfssljson -bare ca -

# ç”Ÿæˆapiserverè¯ä¹¦
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server

#  ç”Ÿæˆkube-proxyè¯ä¹¦
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy

cp /root/TLS/k8s/{ca*pem,server.pem,server-key.pem} /opt/kubernetes/ssl/
```

2. å®‰è£… `kubernetes` åŒ…

``` bash
mkdir /opt/kubernetes/{bin,cfg,ssl,logs} -p
tar -zxvf kubernetes-server-linux-amd64.tar.gz ./
cd kubernetes/server/bin
cp kube-apiserver kube-scheduler kube-controller-manager kubectl /opt/kubernetes/bin
```

3. åˆ›å»º `token.csv` æ–‡ä»¶

``` bash
vi /opt/kubernetes/cfg/token.csv

674c457d4dcf2eefe4920d7dbb6b0ddc,kubelet-bootstrap,10001,"system:node-bootstrapper"

# ç¬¬ä¸€åˆ—: éšæœºå­—ç¬¦ä¸²ï¼Œè‡ªå·±å¯ç”Ÿæˆ
# ç¬¬äºŒåˆ—: ç”¨æˆ·å
# ç¬¬ä¸‰åˆ—: UID
# ç¬¬å››åˆ—: ç”¨æˆ·ç»„
```

4. åˆ›å»º `kube-apiserver.conf` æ–‡ä»¶

``` bash
vi /opt/kubernetes/cfg/kube-apiserver.conf


KUBE_APISERVER_OPTS="--logtostderr=false \
--v=2 \
--log-dir=/opt/kubernetes/logs \
--etcd-servers=https://172.16.199.136:2379,https://172.16.199.137:2379,https://172.16.199.138:2379 \
--bind-address=172.16.199.136 \
--secure-port=6443 \
--advertise-address=172.16.199.136 \
--allow-privileged=true \
--service-cluster-ip-range=10.0.0.0/24 \
--enable-admission-plugins=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota,NodeRestriction \
--authorization-mode=RBAC,Node \
--enable-bootstrap-token-auth=true \
--token-auth-file=/opt/kubernetes/cfg/token.csv \
--service-node-port-range=30000-32767 \
--tls-cert-file=/opt/kubernetes/ssl/server.pem  \
--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \
--client-ca-file=/opt/kubernetes/ssl/ca.pem \
--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \
--etcd-cafile=/opt/etcd/ssl/ca.pem \
--etcd-certfile=/opt/etcd/ssl/server.pem \
--etcd-keyfile=/opt/etcd/ssl/server-key.pem \
--audit-log-maxage=30 \
--audit-log-maxbackup=3 \
--audit-log-maxsize=100 \
--audit-log-path=/opt/kubernetes/logs/k8s-audit.log"



# å‚æ•°è¯´æ˜ï¼š
# â€“logtostderr å¯ç”¨æ—¥å¿—
# â€”v æ—¥å¿—ç­‰çº§
# â€“etcd-servers etcdé›†ç¾¤åœ°å€
# â€“bind-address ç›‘å¬åœ°å€
# â€“secure-port httpså®‰å…¨ç«¯å£
# â€“advertise-address é›†ç¾¤é€šå‘Šåœ°å€
# â€“allow-privileged å¯ç”¨æˆæƒ
# â€“service-cluster-ip-range Serviceè™šæ‹ŸIPåœ°å€æ®µ
# â€“enable-admission-plugins å‡†å…¥æ§åˆ¶æ¨¡å—
# â€“authorization-mode è®¤è¯æˆæƒï¼Œå¯ç”¨RBACæˆæƒå’ŒèŠ‚ç‚¹è‡ªç®¡ç†
# â€“enable-bootstrap-token-auth å¯ç”¨TLS bootstrapåŠŸèƒ½ï¼Œåé¢ä¼šè®²åˆ°
# â€“token-auth-file tokenæ–‡ä»¶
# â€“service-node-port-range Service Nodeç±»å‹é»˜è®¤åˆ†é…ç«¯å£èŒƒå›´
```

5. åˆ›å»º `kube-controller-manager.conf` æ–‡ä»¶

``` bash
vi /opt/kubernetes/cfg/kube-controller-manager.conf

KUBE_CONTROLLER_MANAGER_OPTS="--logtostderr=false \
--v=2 \
--log-dir=/opt/kubernetes/logs \
--leader-elect=true \
--master=127.0.0.1:8080 \
--address=127.0.0.1 \
--allocate-node-cidrs=true \
--cluster-cidr=10.244.0.0/16 \
--service-cluster-ip-range=10.0.0.0/24 \
--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \
--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem  \
--root-ca-file=/opt/kubernetes/ssl/ca.pem \
--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \
--experimental-cluster-signing-duration=87600h0m0s"
```

6. åˆ›å»º `kube-scheduler.conf` æ–‡ä»¶

``` bash
vi /opt/kubernetes/cfg/kube-scheduler.conf

KUBE_SCHEDULER_OPTS="--logtostderr=false \
--v=2 \
--log-dir=/opt/kubernetes/logs \
--leader-elect \
--master=127.0.0.1:8080 \
--address=127.0.0.1"


# å‚æ•°è¯´æ˜ï¼š
# â€“master è¿æ¥æœ¬åœ°apiserver
# â€“leader-elect å½“è¯¥ç»„ä»¶å¯åŠ¨å¤šä¸ªæ—¶ï¼Œè‡ªåŠ¨é€‰ä¸¾ï¼ˆHAï¼‰
```


7. åˆ›å»º `kube-apiserver.service` å¯åŠ¨æ–‡ä»¶

``` bash
# vi /usr/lib/systemd/system/kube-apiserver.service 

[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes

[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserver.conf
ExecStart=/opt/kubernetes/bin/kube-apiserver $KUBE_APISERVER_OPTS
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

8. åˆ›å»º `kube-scheduler.service` å¯åŠ¨æ–‡ä»¶

``` bash
# vi /usr/lib/systemd/system/kube-scheduler.service 

[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes

[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-scheduler.conf
ExecStart=/opt/kubernetes/bin/kube-scheduler $KUBE_SCHEDULER_OPTS
Restart=on-failure

[Install]
WantedBy=multi-user.target
```


9. åˆ›å»º `kube-controller-manager.service` å¯åŠ¨æ–‡ä»¶

``` bash
# vi /usr/lib/systemd/system/kube-controller-manager.service 

[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes

[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-manager.conf
ExecStart=/opt/kubernetes/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTS
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

10. åˆ†åˆ«å¯åŠ¨ `kube-apiserver`, `kube-scheduler`, `kube-controller-manager`

``` bash
systemctl start kube-apiserver
systemctl enable kube-apiserver

systemctl start kube-scheduler
systemctl enable kube-scheduler

systemctl start kube-controller-manager
systemctl enable kube-controller-manager
```

11. éªŒè¯æ˜¯å¦æˆåŠŸ

``` bash
/opt/kubernetes/bin/kubectl get cs
ps aux | grep kube | wc -l #ç»“æœä¸º4 

cp /opt/kubernetes/bin/kubectl /bin/    #æ–¹ä¾¿

tail -f /opt/kubernetes/logs/kube-apiserver.INFO # æŸ¥çœ‹æ—¥å¿—ï¼Œæ²¡æœ‰æ˜æ˜¾çš„é”™è¯¯æç¤º
tail -f /opt/kubernetes/logs/kube-controller-manager.INFO
tail -f /opt/kubernetes/logs/kube-scheduler.INFO
```

12. é…ç½®TLSï¼ŒåŸºäºbootstrapè‡ªåŠ¨é¢å‘è¯ä¹¦

:::tip è¯´æ˜
`Master apiserver` å¯ç”¨ `TLS` è®¤è¯åï¼Œ`Node` èŠ‚ç‚¹ `kubelet` ç»„ä»¶æƒ³è¦åŠ å…¥é›†ç¾¤ï¼Œå¿…é¡»ä½¿ç”¨ `CA` ç­¾å‘çš„æœ‰æ•ˆè¯ä¹¦æ‰èƒ½ä¸ `apiserver` é€šä¿¡
 
å½“NodeèŠ‚ç‚¹å¾ˆå¤šæ—¶ï¼Œç­¾ç½²è¯ä¹¦æ˜¯ä¸€ä»¶å¾ˆç¹ççš„äº‹æƒ…ï¼Œå› æ­¤æœ‰äº† `TLS Bootstrapping` æœºåˆ¶ï¼Œ`kubelet` ä¼šä»¥ä¸€ä¸ªä½æƒé™ç”¨æˆ·è‡ªåŠ¨å‘ `apiserver` ç”³è¯·è¯ä¹¦ï¼Œ`kubelet` çš„è¯ä¹¦ç”± `apiserver` åŠ¨æ€ç­¾ç½²ã€‚
:::

:::tip ä¸¤ä¸ªè¦æ±‚

`kube-apiserver.conf` é…ç½®æ–‡ä»¶ä¸­
1. `--enable-bootstrap-token-auth=true` é…ç½®é¡¹è¦ä¸º `true`
2. `--token-auth-file=/opt/kubernetes/cfg/token.csv` è®°å½•æˆæƒ
:::


``` bash
# å¯ç”¨æˆæƒ
kubectl create clusterrolebinding kubelet-bootstrap \
  --clusterrole=system:node-bootstrapper \
  --user=kubelet-bootstrap
```


## ä¹. éƒ¨ç½²nodeç»„ä»¶

1. å®‰è£…dockerï¼š å¯åŠ¨å®¹å™¨ (æ ¹æ®k8sç‰ˆæœ¬é€‰æ‹©é€‚åˆçš„dockerç‰ˆæœ¬,æ­¤å¤„é€‰æ‹©docker18.09)

2. åœ¨masterä¸Šæ‰§è¡Œ `kubernetes.sh` æ–‡ä»¶

``` bash
# vi /root/TLS/k8s/kubernetes.sh

# åˆ›å»ºkubelet bootstrapping kubeconfig 
BOOTSTRAP_TOKEN=674c457d4dcf2eefe4920d7dbb6b0ddc
KUBE_APISERVER="https://172.16.199.136:6443"

# è®¾ç½®é›†ç¾¤å‚æ•°
kubectl config set-cluster kubernetes \
  --certificate-authority=./ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®å®¢æˆ·ç«¯è®¤è¯å‚æ•°
kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®ä¸Šä¸‹æ–‡å‚æ•°
kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig

# è®¾ç½®é»˜è®¤ä¸Šä¸‹æ–‡
kubectl config use-context default --kubeconfig=bootstrap.kubeconfig

#-------------------------------------------------------------------
#-------------------------------------------------------------------

# åˆ›å»ºkube-proxy kubeconfigæ–‡ä»¶

kubectl config set-cluster kubernetes \
  --certificate-authority=./ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-credentials kube-proxy \
  --client-certificate=./kube-proxy.pem \
  --client-key=./kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
```
 
``` bash
chmod 777 kubernetes.sh # ä¿®æ”¹æ‰§è¡Œæƒé™
./kubernetes.sh # æ‰§è¡Œè„šæœ¬
```

:::tip è¯´æ˜
è¿™æ—¶å¯ä»¥å‘ç°ç”Ÿæˆäº† `bootstrap.kubeconfig` å’Œ `kube-proxy.kubeconfig` ä¸¤ä¸ªæ–‡ä»¶ï¼ˆå¦¥å–„ä¿å­˜ï¼Œä¸€æ—¦æ³„éœ²ï¼Œé›†ç¾¤ç‚¸äº†ï¼‰âš ï¸

å°†è¿™ä¸¤ä¸ªæ–‡ä»¶é€šè¿‡scpå‘é€åˆ°æ‰€æœ‰NodeèŠ‚ç‚¹çš„ `/opt/kubernetes/cfg` ç›®å½•ä¸‹ã€‚
:::

3. masterå‘é€ `kubelet` å’Œ `kube-proxy` è‡³nodeèŠ‚ç‚¹

``` bash
mkdir /opt/kubernetes/{bin,cfg,ssl,logs} -p # nodeèŠ‚ç‚¹æ‰§è¡Œ
```

:::tip è¯´æ˜
è§£å‹ `kubernetes-server-linux-amd64.tar.gz` åï¼Œåœ¨ `/kubernetes/server/bin` ä¸‹æ‰¾åˆ° `kubelet` å’Œ `kube-proxy` ä¸¤ä¸ªæ–‡ä»¶ï¼Œå°†è¿™ä¸¤ä¸ªæ–‡ä»¶æ‹·è´åˆ°NodeèŠ‚ç‚¹çš„ `/opt/kubernetes/bin` ç›®å½•ä¸‹ã€‚
:::

4. masterå‘é€è¯ä¹¦è‡³nodeèŠ‚ç‚¹

``` bash
cd /root/TLS/k8s
scp /root/TLS/k8s/{ca.pem, kube-proxy.pem, kube-proxy-key.pem} root@node:/opt/kubernetes/ssl
```

5. å®‰è£…kubeletï¼š æ¥å—apiserverçš„æŒ‡ä»¤ï¼Œç„¶åæ§åˆ¶dockerå®¹å™¨


> 1) é…ç½® `kubelet-config.yml` æ–‡ä»¶

```
# vi /opt/kubernetes/cfg/kubelet-config.yml

kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 0.0.0.0
port: 10250
readOnlyPort: 10255
cgroupDriver: cgroupfs
clusterDNS:
- 10.0.0.2
clusterDomain: cluster.local
failSwapOn: false
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 2m0s
    enabled: true
  x509:
    clientCAFile: /opt/kubernetes/ssl/ca.pem
authentication:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 5m0s
    cacheUnauthorizedTTL: 30s
evictionHard:
  imagefs.available: 15%
  memory.available: 100Mi
  nodefs.available: 10%
  nodefs.inodesFree: 5%
maxOpenFiles: 1000000
maxPods: 110
```

> 2) é…ç½® `kubelet.conf` æ–‡ä»¶ ï¼ˆæŒ‡å®šå½“å‰ä¸»æœºåï¼‰

```
# vi /opt/kubernetes/cfg/kubelet.conf

KUBELET_OPTS="--logtostderr=false \
--v=2 \
--log-dir=/opt/kubernetes/logs \
--hostname-override=k8s-node01 \
--network-plugin=cni \
--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \
--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \
--config=/opt/kubernetes/cfg/kubelet-config.yml \
--cert-dir=/opt/kubernetes/ssl \
--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0"
```

> 3) é…ç½® `kubelet.service` æ–‡ä»¶

```
# vi /usr/lib/systemd/system/kubelet.service

[Unit]
Description=Kubernetes Kubelet
After=docker.service
Requires=docker.service

[Service]
EnvironmentFile=/opt/kubernetes/cfg/kubelet.conf
ExecStart=/opt/kubernetes/bin/kubelet $KUBELET_OPTS
Restart=on-failure
KillMode=process

[Install]
WantedBy=multi-user.target
```

> 4) å¯åŠ¨ `kubelet`

```
systemctl start kubelet
systemctl enable kubelet
```

- 3. å®‰è£…kube-proxyï¼šä¸ºnodeä¸Šçš„å®¹å™¨é…ç½®ç½‘ç»œåŠŸèƒ½


> 1) é…ç½® `kube-proxy-config.yml` (æŒ‡å®šå½“å‰ä¸»æœºå)

```
vi /opt/kubernetes/cfg/kube-proxy-config.yml

kind: KubeProxyConfiguration
apiVersion: kubeproxy.config.k8s.io/v1alpha1
address: 0.0.0.0
metricsBindAddress: 0.0.0.0:10249
clientConnection:
  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig
hostnameoverride: k8s-node01
clusterCIDR: 10.0.0.0/24
mode: ipvs
ipvs:
  scheduler: "rr"
iptables:
  masqueradeAll: true
```


> 2) é…ç½® `kube-proxy.conf`

```
vi /opt/kubernetes/cfg/kube-proxy.conf

KUBE_PROXY_OPTS="--logtostderr=false \
--v=2 \
--log-dir=/opt/kubernetes/logs \
--config=/opt/kubernetes/cfg/kube-proxy-config.yml"
```

> 3) é…ç½® `kube-proxy.service` é…ç½®æ–‡ä»¶

```
# vi /usr/lib/systemd/system/kube-proxy.service

[Unit]
Description=Kubernetes Proxy
After=network.target

[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-proxy.conf
ExecStart=/opt/kubernetes/bin/kube-proxy $KUBE_PROXY_OPTS
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

> 4) å¯åŠ¨ `kube-proxy` æœåŠ¡

```
systemctl start kube-proxy
systemctl enable kube-proxy
```

- 4. åœ¨masterèŠ‚ç‚¹ç»™nodeèŠ‚ç‚¹é¢å‘è¯ä¹¦

> åœ¨nodeèŠ‚ç‚¹å¯åŠ¨kubectlæ—¶ï¼Œä¼šå‘masterèŠ‚ç‚¹è¯·æ±‚ç”³è¯·è¯ä¹¦

```
kubectl get csr #åœ¨masterèŠ‚ç‚¹æŸ¥çœ‹
kubectl certificate approve node-csr-b5WX_MrzTr3HOcf5ecjKmJNoFkbpKTTgWZLwOA1YQ48 #é¢å‘è¯ä¹¦
kubectl get nodes # åœ¨masterèŠ‚ç‚¹ä¸Šå¯ä»¥æŸ¥çœ‹ï¼ŒnodeèŠ‚ç‚¹å·²ç»åŠ å…¥é›†ç¾¤ ï¼ˆå¯èƒ½éœ€è¦ç‚¹æ—¶é—´ï¼Œ1minï¼‰
```

## å. éƒ¨ç½²k8sé›†ç¾¤ç½‘ç»œ

1. ç¡®è®¤å¯ç”¨CNIæ’ä»¶

``` bash
grep "cni" /opt/kubernetes/cfg/kubelet.conf
```

2. åˆ›å»ºç›®å½•

``` bash
mkdir -pv /opt/cni/bin /etc/cni/net.d
```

3. ç¦»çº¿å®‰è£…

``` bash
tar xf cni-plugins-linux-amd64-v0.8.5.tgz -C /opt/cni/bin/
```

4. ä¸‹è½½

``` bash
wget https://github.com/coreos/flannel/releases/download/v0.10.0/flannel-v0.10.0-linux-amd64.tar.gz
```

 
5. åœ¨ `master` èŠ‚ç‚¹åˆ›å»º `kube-flannel.yaml` æ–‡ä»¶

``` bash
vi kube-flannel.yaml

---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: psp.flannel.unprivileged
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
spec:
  privileged: false
  volumes:
    - configMap
    - secret
    - emptyDir
    - hostPath
  allowedHostPaths:
    - pathPrefix: "/etc/cni/net.d"
    - pathPrefix: "/etc/kube-flannel"
    - pathPrefix: "/run/flannel"
  readOnlyRootFilesystem: false
  # Users and groups
  runAsUser:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  # Privilege Escalation
  allowPrivilegeEscalation: false
  defaultAllowPrivilegeEscalation: false
  # Capabilities
  allowedCapabilities: ['NET_ADMIN']
  defaultAddCapabilities: []
  requiredDropCapabilities: []
  # Host namespaces
  hostPID: false
  hostIPC: false
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  # SELinux
  seLinux:
    # SELinux is unsed in CaaSP
    rule: 'RunAsAny'
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
rules:
  - apiGroups: ['extensions']
    resources: ['podsecuritypolicies']
    verbs: ['use']
    resourceNames: ['psp.flannel.unprivileged']
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes/status
    verbs:
      - patch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flannel
  namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kube-flannel-cfg
  namespace: kube-system
  labels:
    tier: node
    app: flannel
data:
  cni-conf.json: |
    {
      "cniVersion": "0.2.0",
      "name": "cbr0",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-amd64
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - amd64
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: lizhenliang/flannel:v0.11.0-amd64 
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: lizhenliang/flannel:v0.11.0-amd64 
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
```


- 4. åœ¨masterä¸Šæ‰§è¡Œyamlè„šæœ¬ï¼Œå®ç°åœ¨nodeèŠ‚ç‚¹å®‰è£…å¯åŠ¨ç½‘ç»œæ’ä»¶åŠŸèƒ½

```
kubectl apply -f kube-flannel.yaml #æ‰§è¡Œ
kubectl delete -f kube-flannel.yaml #åˆ é™¤

kubectl get pods -n kube-system #æŸ¥çœ‹æ˜¯å¦å·²ç»æ‰§è¡ŒæˆåŠŸ  STATUSä¸ºRunning
kubectl get nodes #è‹¥å·²ç»æˆåŠŸï¼ŒæŸ¥çœ‹nodeèŠ‚ç‚¹çš„çŠ¶æ€ï¼Œåˆ™è¯¥å‘½ä»¤STATUSä¹Ÿä¼šå˜ä¸ºReady
```

- 5. åœ¨masteræˆæƒapiserverå¯ä»¥è®¿é—®kubelet

```
kubectl apply -f apiserver-to-kubelet-rbac.yaml #æ‰§è¡Œ
kubectl describe node k8s-node02 #æ£€æŸ¥k8s-node02èŠ‚ç‚¹
```


## åä¸€. å¯åŠ¨ä¸€ä¸ªnginxå®¹å™¨


```
# ç”Ÿäº§å¼€å‘ä¸­å»ºè®®æŠŠé•œåƒåŒ…ä¸‹è½½å¥½ï¼Œé€šè¿‡saveå’Œloadè¿›è¡Œé•œåƒæ“ä½œ

1) ä¿®æ”¹/etc/docker/daemon.json
2) é‡å¯

systemctl daemon-reload
systemctl restart docker

3) åœ¨masterå¯åŠ¨nginx
kubectl create deployment myweb --image=nginx:1.8   #åˆ›å»ºdeploymentï¼Œé€šè¿‡deploymentæ¥åˆ›å»ºå’Œç®¡ç†nginxå®¹å™¨
kubectl get deployment  #æŸ¥çœ‹deploymentçŠ¶æ€
kubectl get pods        #æŸ¥çœ‹podsçŠ¶æ€


### test 
kubectl create deployment myweb1 --image=nginx:1.6
kubectl get pods 
kubectl describe pod myweb1-6ff756695f-l9qwc.  #ï¼ˆæ’æŸ¥æ•…éšœç»å¸¸ç”¨ï¼‰#æŸ¥çœ‹Nodeï¼Œæ˜¾ç¤ºnginxåœ¨å“ªä¸ªæœåŠ¡å™¨å¯åŠ¨

```

4) masterå°†å®¹å™¨çš„ç«¯å£æš´éœ²ç»™å®¿ä¸»æœº

```
kubectl expose deployment myweb --port=80 --type=NodePort
kubectl get service   #æŸ¥çœ‹æ˜ å°„
kubectl get svc     #svc serviceçš„ç®€å†™

# è®¿é—®ä»»æ„nodeèŠ‚ç‚¹éƒ½å¯ä»¥è®¿é—®
# http://172.16.199.131:31155
# http://172.16.199.132:31155
```


## åäºŒ. éƒ¨ç½²webç®¡ç†ç•Œé¢ ï¼ˆdashboardï¼‰

- kubernetes dashboard ï¼ˆå®˜æ–¹ï¼‰

```
kubectl apply -f dashboard.yaml  #å®‰è£…
kubectl get pods -n kubernetes-dashboard #æŸ¥çœ‹kubernetes-dashboardå‘½åç©ºé—´çš„pod

kubectl get service -n kubernetes-dashboard #æŸ¥çœ‹kubernetes-dashboardå‘½åç©ºé—´çš„service

```

> åœ¨chromeè¯¥é¡µé¢ä¸Šï¼Œç›´æ¥é”®ç›˜æ•²å…¥è¿™11ä¸ªå­—ç¬¦ï¼šthisisunsafe
ï¼ˆé¼ æ ‡ç‚¹å‡»å½“å‰é¡µé¢ä»»æ„ä½ç½®ï¼Œè®©é¡µé¢å¤„äºæœ€ä¸Šå±‚å³å¯è¾“å…¥ï¼‰


- kuboard (ç¬¬ä¸‰æ–¹)(æ¨è)

```
docker pull eipwork/kuboard. #åœ¨nodeèŠ‚ç‚¹ä¸Šä¸‹è½½é•œåƒ

kubectl apply -f https://kuboard.cn/install-script/kuboard.yaml #åœ¨masterèŠ‚ç‚¹æ‰§è¡Œ
# å¯æ·»åŠ nodeName: k8s-node01 æŒ‡å®šè¿è¡Œåœ¨å“ªä¸ªèŠ‚ç‚¹

kubectl get pods -n kube-system #æŸ¥çœ‹å‘½åç©ºé—´
kubectl get service -n kube-system #æŸ¥çœ‹æœåŠ¡ç«¯å£


echo $(kubectl -n kube-system get secret $(kubectl -n kube-system get secret | grep kuboard-user | awk '{print $1}') -o go-template='{{.data.token}}' | base64 -d)  #ç”Ÿæˆtoken æ ¹æ®tokenç™»å½•è®¿é—®
```



## åä¸‰. éƒ¨ç½²é›†ç¾¤å†…éƒ¨DNSè§£ææœåŠ¡ ï¼ˆcoreDNSï¼‰

- åˆ›å»º `coredns.yaml` æ–‡ä»¶

```
# Warning: This is a file generated from the base underscore template file: coredns.yaml.base

apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
  labels:
      kubernetes.io/cluster-service: "true"
      addonmanager.kubernetes.io/mode: Reconcile
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
    addonmanager.kubernetes.io/mode: Reconcile
  name: system:coredns
rules:
- apiGroups:
  - ""
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
    addonmanager.kubernetes.io/mode: EnsureExists
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
  labels:
      addonmanager.kubernetes.io/mode: EnsureExists
data:
  Corefile: |
    .:53 {
        errors
        health
        kubernetes cluster.local in-addr.arpa ip6.arpa {
            pods insecure
            upstream
            fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        proxy . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "CoreDNS"
spec:
  # replicas: not specified here:
  # 1. In order to make Addon Manager do not reconcile this replicas parameter.
  # 2. Default is 1.
  # 3. Will be tuned in real time if DNS horizontal auto-scaling is turned on.
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
      annotations:
        seccomp.security.alpha.kubernetes.io/pod: 'docker/default'
    spec:
      serviceAccountName: coredns
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        - key: "CriticalAddonsOnly"
          operator: "Exists"
      containers:
      - name: coredns
        image: lizhenliang/coredns:1.2.2
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        args: [ "-conf", "/etc/coredns/Corefile" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: "9153"
    prometheus.io/scrape: "true"
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: "CoreDNS"
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.0.0.2 
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP

```

- æ‰§è¡Œ

``` bash
kubectl apply -f coredns.yaml  #å®‰è£…
kubectl get pods -n kube-system | grep coredns #æŸ¥çœ‹
```

## åå››. è¿œç¨‹ç®¡ç†k8s

é»˜è®¤æƒ…å†µä¸‹ï¼Œk8sä»…ä»…å¯ä»¥åœ¨masterèŠ‚ç‚¹è¿›è¡Œç®¡ç†

``` bash
# åœ¨nodeèŠ‚ç‚¹è¿è¡Œ 
kubectl  #kubectl: æœªæ‰¾åˆ°å‘½ä»¤
# å³ä½¿æœ‰å‘½ä»¤
The connection to the server localhost:8080 was refused - did you specify the right host or port?
```

1. ç”Ÿæˆç®¡ç†å‘˜è¯ä¹¦

``` bash
# åœ¨masteræ‰§è¡Œ
vi admin-csr.json
```


2. é¢å‘adminè¯ä¹¦

``` bash bash
cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin
```

3. åˆ›å»º `kubeconfig` æ–‡ä»¶


``` bash
vi /opt/kubernetes/cfg/kube-proxy.kubeconfig  #æŒ‡å®šä¸ºmasterip
vi /opt/kubernetes/cfg/bootstrap.kubeconfig #æŒ‡å®šmasterip
```








